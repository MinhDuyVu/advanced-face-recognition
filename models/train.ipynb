{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa4c7ba8",
      "metadata": {
        "id": "aa4c7ba8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a1f63e",
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_SIZE = (160, 160)\n",
        "LR = 1e-4\n",
        "MARGIN = 0.2\n",
        "EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def preprocess_face(face, size=INPUT_SIZE):\n",
        "    face = cv2.resize(face, size)\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = tf.keras.applications.mobilenet_v2.preprocess_input(face.astype('float32'))\n",
        "    return face\n",
        "\n",
        "\n",
        "def build_classification_model(n_classes):\n",
        "\tbase = keras.applications.MobileNetV2(include_top=False, input_shape=INPUT_SIZE + (3, ), pooling='avg')\n",
        "\tfor layer in base.layers[:-30]:\n",
        "\t\tlayer.trainable = False\n",
        "\tx = keras.layers.Dense(256, activation='relu')(base.output)\n",
        "\tx = keras.layers.Dropout(0.3)(x)\n",
        "\toutput = keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "\tmodel = keras.Model(base.input, output)\n",
        "\tmodel.compile(optimizer=keras.optimizers.Adam(LR), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def triplet_loss(_, y_pred):\n",
        "\ta, p, n = tf.split(y_pred, 3, axis=0)\n",
        "\td_ap = tf.reduce_sum(tf.square(a - p), 1)\n",
        "\td_an = tf.reduce_sum(tf.square(a - n), 1)\n",
        "\treturn tf.reduce_mean(tf.maximum(d_ap - d_an + MARGIN, 0.0))\n",
        "\n",
        "\n",
        "def build_metric_embedding():\n",
        "\tbase = keras.applications.MobileNetV2(include_top=False, input_shape=INPUT_SIZE + (3, ), pooling='avg')\n",
        "\tx = keras.layers.Dense(256)(base.output)\n",
        "\tx = keras.layers.Lambda(lambda t: tf.math.l2_normalize(t, axis=1))(x)\n",
        "\tmodel = keras.Model(base.input, x)\n",
        "\tmodel.compile(optimizer=keras.optimizers.Adam(LR), loss=triplet_loss)\n",
        "\treturn model\n",
        "\n",
        "\n",
        "def make_triplet_dataset(root, batch_size):\n",
        "\tclasses = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
        "\tlabel2imgs = {c: [os.path.join(root, c, f) for f in os.listdir(os.path.join(root, c))] for c in classes}\n",
        "\twhile True:\n",
        "\t\tA, P, N = [], [], []\n",
        "\t\tfor _ in range(batch_size):\n",
        "\t\t\ta_lbl = random.choice(classes)\n",
        "\t\t\tp_lbl = a_lbl\n",
        "\t\t\tn_lbl = random.choice([l for l in classes if l != a_lbl])\n",
        "\t\t\ta_img, p_img = random.sample(label2imgs[a_lbl], 2)\n",
        "\t\t\tn_img = random.choice(label2imgs[n_lbl])\n",
        "\t\t\tA.append(preprocess_face(cv2.imread(a_img)))\n",
        "\t\t\tP.append(preprocess_face(cv2.imread(p_img)))\n",
        "\t\t\tN.append(preprocess_face(cv2.imread(n_img)))\n",
        "\t\tyield np.concatenate([A, P, N], 0), np.zeros((batch_size * 3, ))\n",
        "\n",
        "\n",
        "def train_classification(train_dir, val_dir, epochs, batch_size):\n",
        "\t# Training data with augmentation\n",
        "\ttrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "\t\tpreprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "\t\trotation_range=15, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True\n",
        "\t)\n",
        "\t# Validation data without augmentation (only rescaling)\n",
        "\tval_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "\t\tpreprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "\t)\n",
        "\t\n",
        "\ttrain = train_datagen.flow_from_directory(\n",
        "\t\ttrain_dir, target_size=INPUT_SIZE, batch_size=batch_size, class_mode='sparse'\n",
        "\t)\n",
        "\tval = val_datagen.flow_from_directory(\n",
        "\t\tval_dir, target_size=INPUT_SIZE, batch_size=batch_size, class_mode='sparse'\n",
        "\t)\n",
        "\t\n",
        "\tmodel = build_classification_model(train.num_classes)\n",
        "\tcallbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)]\n",
        "\tmodel.fit(train, validation_data=val, epochs=epochs, callbacks=callbacks)\n",
        "\tmodel.save('classification_model.keras')\n",
        "\tembedding_model = keras.Model(model.input, model.layers[-2].output)\n",
        "\tembedding_model.save('classification_embedding.keras')\n",
        "\n",
        "\n",
        "def train_metric(train_dir, epochs, batch_size):\n",
        "\tmodel = build_metric_embedding()\n",
        "\tdataset = make_triplet_dataset(train_dir, batch_size)\n",
        "\tclasses = [d for d in os.listdir(train_dir) if os.path.isdir(os.path.join(train_dir, d))]\n",
        "\tsteps_per_epoch = max(100, len(classes) * 2)\n",
        "\tcallbacks = [keras.callbacks.EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)]\n",
        "\tmodel.fit(dataset, steps_per_epoch=steps_per_epoch, epochs=epochs, callbacks=callbacks)\n",
        "\tmodel.save('metric_embedding.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89KTC3wBO2Aw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "89KTC3wBO2Aw",
        "outputId": "9b71bd2f-63ba-4068-bcdb-3ff2f130c263"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3NZXE8GvPLqg",
      "metadata": {
        "id": "3NZXE8GvPLqg"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Projects/advanced-face-recognition/datasets/dataset.zip'\n",
        "train_dir = '/content/classification_data/train_data'\n",
        "val_dir = '/content/classification_data/val_data'\n",
        "\n",
        "!unzip -q \"$data_path\" -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y5FMF6wob-tD",
      "metadata": {
        "id": "Y5FMF6wob-tD"
      },
      "outputs": [],
      "source": [
        "train_classification(train_dir, val_dir, EPOCHS, BATCH_SIZE)\n",
        "\n",
        "!cp classification_model.keras /content/drive/MyDrive/Projects/advanced-face-recognition/\n",
        "!cp classification_embedding.keras /content/drive/MyDrive/Projects/advanced-face-recognition/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f3c39a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_metric(train_dir, EPOCHS, BATCH_SIZE)\n",
        "\n",
        "!cp metric_embedding.keras /content/drive/MyDrive/Projects/advanced-face-recognition/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
